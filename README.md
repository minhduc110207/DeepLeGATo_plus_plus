# DeepLeGATo++

## Next-Generation Galaxy Morphology Estimation with Transformers and Neural Posterior Estimation

**Python 3.9+** | **PyTorch 2.0+** | **MIT License** | **Optimized for Google Colab**

---

## What Is This?

**DeepLeGATo++** (Deep Learning Galaxy Tool++) is a deep learning framework for **automated galaxy morphology estimation**. Given an image of a galaxy, the model predicts the structural parameters that describe its shape, size, brightness, and orientation â€” along with **full uncertainty quantification** for each prediction.

This is critical in astrophysics: understanding galaxy morphology helps scientists study galaxy formation, evolution, and the large-scale structure of the universe. Traditional methods (like GALFIT) require manual fitting and are extremely slow for large surveys. DeepLeGATo++ automates this process using modern neural networks, processing thousands of galaxies in seconds.

### The Problem

Modern astronomical surveys (HST, JWST, Euclid, Rubin/LSST) produce **millions of galaxy images**. Each galaxy needs to be characterized by its **SÃ©rsic profile** â€” a mathematical model that describes how a galaxy's brightness falls off from its center. Fitting these profiles traditionally requires:

- Manual initial parameter guesses
- Iterative optimization (slow, often fails)
- No built-in uncertainty estimates
- Hours per galaxy for complex cases

### The Solution

DeepLeGATo++ uses a **Swin Transformer V2** (a state-of-the-art vision model) combined with **Neural Posterior Estimation** (NPE) to:

1. **Extract multi-scale features** from galaxy images using the Swin Transformer backbone
2. **Estimate the full posterior distribution** of SÃ©rsic parameters using normalizing flows
3. **Provide calibrated uncertainties** â€” not just a point estimate, but a probability distribution over all possible parameter values
4. **Process galaxies in batches** â€” thousands of galaxies per minute on a single GPU

---

## ðŸ”­ What Does the Model Predict?

The model estimates **7 SÃ©rsic profile parameters** for each galaxy image:

| Parameter | Symbol | Description | Prior Range |
|-----------|--------|-------------|-------------|
| **Magnitude** | mag | Total integrated brightness of the galaxy | [15, 28] mag |
| **Effective Radius** | R_eff | Half-light radius (size of the galaxy) | [0.1", 10"] |
| **SÃ©rsic Index** | n | Controls the shape of the light profile (n=1: exponential disk, n=4: de Vaucouleurs elliptical) | [0.3, 8] |
| **Axis Ratio** | q | Ellipticity (1 = circular, 0.1 = highly elongated) | [0.1, 1.0] |
| **Position Angle** | PA | Orientation of the galaxy's major axis | [0Â°, 180Â°] |
| **Center X** | xâ‚€ | Horizontal offset from image center | [Â±5 px] |
| **Center Y** | yâ‚€ | Vertical offset from image center | [Â±5 px] |

For each parameter, the model outputs:
- **Point estimate** (mean prediction)
- **Uncertainty** (standard deviation)
- **95% credible interval** (Bayesian confidence bounds)
- **Full posterior samples** (for custom analysis)

---

## How Does It Work?

### Architecture

```
                    DeepLeGATo++ Architecture
                    
Galaxy Image â”€â”€â†’ Swin Transformer V2 â”€â”€â†’ NPE Head â”€â”€â†’ Posterior Distribution
  (128Ã—128)         (Backbone)           (Flow)         (7 parameters)
                        â”‚                   â”‚
                  Multi-scale          Normalizing
                   Feature              Flows (MAF)
                  Extraction           Conditional on
                                      image features
```

1. **Swin Transformer V2 Backbone**: A hierarchical vision transformer that processes the galaxy image at multiple scales. It uses shifted windows for efficient self-attention, capturing both local details (galaxy center, spiral arms) and global structure (overall shape, orientation). Gradient checkpointing enables training on limited GPU memory.

2. **Neural Posterior Estimation (NPE) Head**: Instead of just predicting a single value for each parameter, the NPE head learns the full posterior distribution p(Î¸|x) â€” the probability of each possible parameter value given the observed image. This is done using **Masked Autoregressive Flows** (MAF), a type of normalizing flow that can model complex, multi-modal distributions.

3. **Parameter Transformation**: Since morphological parameters have physical bounds (e.g., axis ratio must be between 0 and 1), a sigmoid/logit transformation maps between the bounded physical space and an unbounded latent space where the flow operates.

### Training

- **Simulation-Based Inference (SBI)**: The model is trained entirely on **synthetic galaxy images** generated by a GPU-accelerated SÃ©rsic simulator with realistic noise (Poisson shot noise, read noise, sky background) and PSF convolution
- **Loss Function**: Combines Gaussian negative log-likelihood (for point estimates) with flow loss (for posterior estimation)
- **Self-supervised**: No real labeled data needed â€” the simulator generates ground truth parameters

---

## Quick Start (Google Colab)

1. Upload this folder to Google Drive as `My Drive/DeepLeGATo++/`
2. Open `notebooks/03_Training.ipynb` in Google Colab
3. Run all cells â€” training auto-resumes on disconnect!

```python
# Mount Drive and setup
from google.colab import drive
drive.mount('/content/drive')

import sys
sys.path.insert(0, '/content/drive/MyDrive/DeepLeGATo++')

# Install dependencies
!pip install -q torch pytorch-lightning timm nflows einops

# Start training
from deeplegato_pp.training import train
model = train(resume=True)
```

### Inference Example

```python
from deeplegato_pp.inference import Predictor
from deeplegato_pp.models import DeepLeGAToPP

# Load trained model
model = DeepLeGAToPP.load_pretrained("path/to/checkpoint")
predictor = Predictor(model, device="cuda")

# Predict galaxy parameters with uncertainties
result = predictor.predict(galaxy_image, num_samples=1000)
predictor.print_results(result)

# Output:
# Parameter        Mean Â± Std       95% CI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Magnitude      22.34 Â± 0.15    [22.05, 22.63]
# R_eff           1.82 Â± 0.08    [ 1.67,  1.98]
# SÃ©rsic n        2.41 Â± 0.23    [ 1.97,  2.86]
# Axis ratio      0.67 Â± 0.03    [ 0.61,  0.73]
# PA            127.5Â° Â± 2.1Â°   [123.4Â°, 131.6Â°]
```

---

## ðŸ“ Project Structure

```
DeepLeGATo++/
â”œâ”€â”€ configs/                 # YAML configuration files
â”‚   â””â”€â”€ colab_t4.yaml        # Config for T4 GPU (16GB)
â”œâ”€â”€ deeplegato_pp/           # Main Python package
â”‚   â”œâ”€â”€ models/              # Neural network architectures
â”‚   â”‚   â”œâ”€â”€ swin_backbone.py # Swin Transformer V2 feature extractor
â”‚   â”‚   â”œâ”€â”€ npe_head.py      # Normalizing flow posterior estimator
â”‚   â”‚   â””â”€â”€ deeplegato_pp.py # Combined model
â”‚   â”œâ”€â”€ data/                # Data generation & loading
â”‚   â”‚   â”œâ”€â”€ sersic_simulator.py  # GPU-accelerated galaxy simulator
â”‚   â”‚   â”œâ”€â”€ psf_handler.py       # Point Spread Function handling
â”‚   â”‚   â””â”€â”€ dataset.py           # PyTorch datasets & dataloaders
â”‚   â”œâ”€â”€ training/            # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ trainer.py       # PyTorch Lightning trainer
â”‚   â”‚   â”œâ”€â”€ losses.py        # NPE & physics-informed losses
â”‚   â”‚   â””â”€â”€ colab_utils.py   # Google Colab helpers
â”‚   â””â”€â”€ inference/           # Prediction & analysis
â”‚       â”œâ”€â”€ predictor.py     # High-level prediction interface
â”‚       â””â”€â”€ uncertainty.py   # Calibration & UQ utilities
â”œâ”€â”€ notebooks/               # Jupyter/Colab notebooks
â””â”€â”€ requirements.txt         # Python dependencies
```

---

## GPU Requirements

| GPU | VRAM | Batch Size | Estimated Training Time |
|-----|------|------------|------------------------|
| T4 (Colab Free) | 16 GB | 16 | ~8 hours |
| L4 (Colab Pro) | 24 GB | 32 | ~4 hours |
| A100 (Colab Pro+) | 40 GB | 64 | ~2 hours |

---

## ðŸ”¬ Scientific Background

### SÃ©rsic Profile

The SÃ©rsic profile is the standard model for describing galaxy surface brightness:

```
$I(r) = I_e Ã— exp( -b_n Ã— [(r/R_e)^(1/n) - 1] )$
```

Where:
- **I_e** is the intensity at the effective radius
- **R_e** is the effective (half-light) radius
- **n** is the SÃ©rsic index (shape parameter)
- **b_n** â‰ˆ 2n - 1/3 (normalization constant)

Different values of n correspond to different galaxy types:
- **n â‰ˆ 0.5**: Gaussian profile
- **n â‰ˆ 1**: Exponential disk (spiral galaxies)
- **n â‰ˆ 4**: de Vaucouleurs profile (elliptical galaxies)
- **n > 4**: Centrally concentrated profiles (giant ellipticals)

### Neural Posterior Estimation

Unlike traditional methods that find a single best-fit, NPE learns the full posterior distribution p(Î¸|x), answering: *"Given this galaxy image, what are all the plausible parameter values and how likely is each?"* This is achieved using conditional normalizing flows â€” invertible neural networks that transform a simple base distribution into a complex posterior, conditioned on the image features.

---

## Built With

- [PyTorch](https://pytorch.org/) â€” Deep learning framework
- [PyTorch Lightning](https://lightning.ai/) â€” Training infrastructure
- [timm](https://github.com/huggingface/pytorch-image-models) â€” Swin Transformer V2 implementation
- [nflows](https://github.com/bayesiains/nflows) â€” Normalizing flows for NPE
- [Astropy](https://www.astropy.org/) â€” FITS file handling

---

## ðŸ“– References

- **Original DeepLeGATo**: Tuccillo et al., *"Deep learning for galaxy surface brightness profile fitting"*, MNRAS, 2018 ([arXiv:1711.03108](https://arxiv.org/abs/1711.03108))
- **Swin Transformer V2**: Liu et al., *"Swin Transformer V2: Scaling Up Capacity and Resolution"*, CVPR, 2022
- **Neural Posterior Estimation**: Papamakarios et al., *"Sequential Neural Likelihood"*, AISTATS, 2019
- **SÃ©rsic Profile**: SÃ©rsic, J.L., *"Influence of the atmospheric and instrumental dispersion on the brightness distribution in a galaxy"*, 1963

## Citation

If you use DeepLeGATo++ in your research, please cite:

```bibtex
@article{deeplegato_pp_2025,
  title={DeepLeGATo++: Galaxy Profile Fitting with Transformers and Neural Posterior Estimation},
  year={2025}
}

@article{tuccillo2018deep,
  title={Deep learning for galaxy surface brightness profile fitting},
  author={Tuccillo, D. and others},
  journal={MNRAS},
  year={2018}
}
```

## License

MIT License â€” see [LICENSE](LICENSE) for details.
