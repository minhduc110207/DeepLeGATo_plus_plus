{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üåå DeepLeGATo++ Training Notebook\n",
                "\n",
                "**Next-Generation Galaxy Profile Fitting with Transformers and Neural Posterior Estimation**\n",
                "\n",
                "This notebook trains DeepLeGATo++ on Google Colab with automatic:\n",
                "- GPU detection and config selection\n",
                "- Checkpoint saving to Google Drive\n",
                "- Resume from previous checkpoints"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1Ô∏è‚É£ Setup & Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mount Google Drive\n",
                "from google.colab import drive\n",
                "drive.mount('/content/drive')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup project from Google Drive\n",
                "import os\n",
                "import sys\n",
                "\n",
                "PROJECT_NAME = \"DeepLeGATo++\"\n",
                "DRIVE_PATH = f\"/content/drive/MyDrive/{PROJECT_NAME}\"\n",
                "\n",
                "# Check if code exists on Drive\n",
                "if os.path.exists(f\"{DRIVE_PATH}/deeplegato_pp\"):\n",
                "    print(\"‚úÖ Project found on Google Drive!\")\n",
                "    !cp -r \"{DRIVE_PATH}/deeplegato_pp\" /content/\n",
                "    !cp -r \"{DRIVE_PATH}/configs\" /content/\n",
                "    sys.path.insert(0, '/content')\n",
                "else:\n",
                "    print(\"‚ùå Project not found! Please upload DeepLeGATo++ folder to Google Drive.\")\n",
                "    print(f\"Expected path: {DRIVE_PATH}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies\n",
                "!pip install -q torch>=2.1.0 pytorch-lightning>=2.1.0 timm>=0.9.12\n",
                "!pip install -q nflows zuko astropy photutils\n",
                "!pip install -q wandb gradio plotly seaborn\n",
                "!pip install -q einops pyyaml\n",
                "print(\"‚úÖ Dependencies installed!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify GPU\n",
                "import torch\n",
                "\n",
                "print(\"=\" * 50)\n",
                "print(\"GPU Information\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    gpu_name = torch.cuda.get_device_name(0)\n",
                "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
                "    print(f\"‚úÖ GPU: {gpu_name}\")\n",
                "    print(f\"‚úÖ VRAM: {vram:.1f} GB\")\n",
                "else:\n",
                "    print(\"‚ùå No GPU available!\")\n",
                "    print(\"Go to Runtime > Change runtime type > GPU\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2Ô∏è‚É£ Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deeplegato_pp.training.colab_utils import (\n",
                "    setup_drive_paths,\n",
                "    auto_select_config,\n",
                "    get_latest_checkpoint,\n",
                ")\n",
                "\n",
                "# Setup paths on Drive\n",
                "paths = setup_drive_paths(PROJECT_NAME)\n",
                "print(\"\\nProject paths:\")\n",
                "for name, path in paths.items():\n",
                "    print(f\"  {name}: {path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import yaml\n",
                "\n",
                "# Auto-select config based on GPU\n",
                "config_path = auto_select_config(\"/content/configs\")\n",
                "\n",
                "with open(config_path, 'r') as f:\n",
                "    config = yaml.safe_load(f)\n",
                "\n",
                "print(f\"\\nUsing config: {config_path}\")\n",
                "print(f\"\\nKey settings:\")\n",
                "print(f\"  Backbone: {config['model']['backbone']['type']}\")\n",
                "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
                "print(f\"  Accumulation: {config['training']['accumulation_steps']}\")\n",
                "print(f\"  Effective batch: {config['training']['batch_size'] * config['training']['accumulation_steps']}\")\n",
                "print(f\"  Max epochs: {config['training']['max_epochs']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3Ô∏è‚É£ Initialize Model & Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deeplegato_pp.models import DeepLeGAToPP\n",
                "from deeplegato_pp.data import create_dataloaders\n",
                "\n",
                "# Create model\n",
                "model = DeepLeGAToPP.from_config(config)\n",
                "\n",
                "# Print model info\n",
                "param_counts = model.count_parameters()\n",
                "print(f\"\\nüìä Model Parameters:\")\n",
                "print(f\"  Total: {param_counts['total']:,}\")\n",
                "print(f\"  Trainable: {param_counts['trainable']:,}\")\n",
                "print(f\"  Backbone: {param_counts['backbone']:,}\")\n",
                "print(f\"  NPE Head: {param_counts['npe_head']:,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataloaders\n",
                "print(\"\\nüìÅ Creating dataloaders...\")\n",
                "train_loader, val_loader = create_dataloaders(config)\n",
                "\n",
                "print(f\"  Training samples: {len(train_loader.dataset):,}\")\n",
                "print(f\"  Validation samples: {len(val_loader.dataset):,}\")\n",
                "print(f\"  Batches per epoch: {len(train_loader):,}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize sample data\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "batch = next(iter(train_loader))\n",
                "images = batch['image']\n",
                "params = batch['params']\n",
                "\n",
                "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
                "for i, ax in enumerate(axes.flatten()):\n",
                "    if i < len(images):\n",
                "        ax.imshow(images[i, 0].cpu(), cmap='viridis')\n",
                "        ax.set_title(f\"n={params[i, 2]:.1f}, Re={params[i, 1]:.1f}\")\n",
                "        ax.axis('off')\n",
                "plt.suptitle(\"Sample Training Data\")\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4Ô∏è‚É£ Training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deeplegato_pp.training import train\n",
                "\n",
                "# Check for existing checkpoint\n",
                "checkpoint = get_latest_checkpoint(paths['checkpoints'])\n",
                "\n",
                "if checkpoint:\n",
                "    print(f\"\\nüîÑ Found checkpoint: {checkpoint}\")\n",
                "    print(\"Training will resume from this checkpoint.\")\n",
                "else:\n",
                "    print(\"\\nüÜï Starting fresh training run.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# üöÄ START TRAINING\n",
                "print(\"\\n\" + \"=\" * 50)\n",
                "print(\"üöÄ STARTING TRAINING\")\n",
                "print(\"=\" * 50)\n",
                "print(\"\\nCheckpoints will be saved to Google Drive automatically.\")\n",
                "print(\"If the session disconnects, re-run this notebook to resume.\\n\")\n",
                "\n",
                "trained_model = train(\n",
                "    config=config,\n",
                "    resume=True,  # Auto-resume from checkpoint\n",
                "    fast_dev_run=False,  # Set True for quick test\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5Ô∏è‚É£ Evaluate Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from deeplegato_pp.training.colab_utils import get_best_checkpoint\n",
                "from deeplegato_pp.inference import Predictor\n",
                "\n",
                "# Load best model\n",
                "best_ckpt = get_best_checkpoint(paths['checkpoints'])\n",
                "if best_ckpt:\n",
                "    print(f\"Loading best checkpoint: {best_ckpt}\")\n",
                "    checkpoint = torch.load(best_ckpt, map_location='cuda')\n",
                "    model.load_state_dict(checkpoint['state_dict'])\n",
                "\n",
                "# Create predictor\n",
                "predictor = Predictor(model, device='cuda')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Test on validation data\n",
                "val_batch = next(iter(val_loader))\n",
                "test_image = val_batch['image'][0:1].cuda()\n",
                "true_params = val_batch['params'][0]\n",
                "\n",
                "# Predict\n",
                "result = predictor.predict(test_image, num_samples=1000, return_samples=True)\n",
                "\n",
                "# Print comparison\n",
                "print(\"\\n\" + \"=\" * 60)\n",
                "print(\"Prediction vs True Values\")\n",
                "print(\"=\" * 60)\n",
                "\n",
                "param_names = [\"magnitude\", \"effective_radius\", \"sersic_index\", \n",
                "               \"axis_ratio\", \"position_angle\", \"center_x\", \"center_y\"]\n",
                "\n",
                "for i, name in enumerate(param_names):\n",
                "    pred = result['params'][name]['value']\n",
                "    std = result['params'][name]['std']\n",
                "    true = true_params[i].item()\n",
                "    error = abs(pred - true)\n",
                "    print(f\"{name:18s}: pred={pred:7.3f} ¬± {std:.3f}  |  true={true:7.3f}  |  error={error:.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot posterior distributions\n",
                "predictor.plot_posterior(result, save_path=str(paths['outputs'] / 'posterior_example.png'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6Ô∏è‚É£ Save Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model to Drive\n",
                "save_path = paths['models'] / 'final_model'\n",
                "model.save_pretrained(save_path)\n",
                "\n",
                "print(f\"\\n‚úÖ Model saved to: {save_path}\")\n",
                "print(\"\\nYou can load this model later with:\")\n",
                "print(f\"  model = DeepLeGAToPP.from_pretrained('{save_path}')\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## üéâ Training Complete!\n",
                "\n",
                "Your trained DeepLeGATo++ model is now saved to Google Drive.\n",
                "\n",
                "**Next steps:**\n",
                "1. Test on real galaxy images\n",
                "2. Export model for deployment\n",
                "3. Fine-tune on specific survey data (JWST, LSST)"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}